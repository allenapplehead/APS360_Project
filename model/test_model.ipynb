{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pretty_midi\n",
    "from model import Net\n",
    "from midi_to_piano_roll import midi_to_piano_roll\n",
    "from loss import blur_loss\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our checkpoint\n",
    "ckpt_path = \"/media/allentao/One Touch/APS360/ckpts/jul30_lr0.01_before_postprocess/checkpoint_epoch116.pt\"\n",
    "state = torch.load(ckpt_path)\n",
    "model = Net(width = 3, batch_size = 1)\n",
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data sample\n",
    "# song midi\n",
    "IN_FOLDER = '../data/clean_data/'\n",
    "song_midi_path = IN_FOLDER + \"1_0_song.midi\"\n",
    "\n",
    "# convert to piano roll\n",
    "song_piano_roll = midi_to_piano_roll(song_midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22705, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run inference\n",
    "model = model.to(device)\n",
    "out = model(song_piano_roll.unsqueeze(0).to(device))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.1290e-05, 3.2980e-05, 5.2028e-05,  ..., 2.9458e-05,\n",
       "          3.6429e-05, 3.0528e-05],\n",
       "         [5.2626e-05, 4.9022e-05, 4.6929e-05,  ..., 2.7359e-05,\n",
       "          3.0954e-05, 3.3607e-05],\n",
       "         [3.9965e-05, 2.1767e-05, 9.3727e-05,  ..., 1.1745e-04,\n",
       "          3.2476e-05, 3.3984e-05],\n",
       "         ...,\n",
       "         [4.6474e-05, 7.1146e-05, 5.9267e-05,  ..., 5.9515e-05,\n",
       "          8.9962e-05, 3.0244e-05],\n",
       "         [4.7898e-05, 2.4365e-05, 3.2893e-05,  ..., 2.5035e-05,\n",
       "          5.0519e-05, 6.4881e-05],\n",
       "         [4.9933e-05, 2.1932e-05, 3.4271e-05,  ..., 3.0191e-05,\n",
       "          6.0375e-05, 2.8528e-05]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Unknown message type 'set_tempo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Convert piano roll to midi file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpianoroll_to_midi\u001b[39;00m \u001b[39mimport\u001b[39;00m piano_roll_to_midi\n\u001b[0;32m----> 4\u001b[0m midi_out \u001b[39m=\u001b[39m piano_roll_to_midi(out\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m midi_out\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mtest.mid\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Melogen/model/pianoroll_to_midi.py:12\u001b[0m, in \u001b[0;36mpiano_roll_to_midi\u001b[0;34m(piano_roll, tempo)\u001b[0m\n\u001b[1;32m      9\u001b[0m track \u001b[39m=\u001b[39m MidiTrack()\n\u001b[1;32m     10\u001b[0m mid\u001b[39m.\u001b[39mtracks\u001b[39m.\u001b[39mappend(track)\n\u001b[0;32m---> 12\u001b[0m track\u001b[39m.\u001b[39mappend(Message(\u001b[39m'\u001b[39;49m\u001b[39mset_tempo\u001b[39;49m\u001b[39m'\u001b[39;49m, tempo\u001b[39m=\u001b[39;49mtempo))\n\u001b[1;32m     14\u001b[0m tick_duration \u001b[39m=\u001b[39m mid\u001b[39m.\u001b[39mticks_per_beat \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m time_step, notes \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(piano_roll):\n",
      "File \u001b[0;32m~/Melogen/aps360/lib/python3.8/site-packages/mido/messages/messages.py:115\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[0;34m(self, type, **args)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 115\u001b[0m     msgdict \u001b[39m=\u001b[39m make_msgdict(\u001b[39mtype\u001b[39;49m, args)\n\u001b[1;32m    116\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msysex\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    117\u001b[0m         msgdict[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m SysexData(msgdict[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Melogen/aps360/lib/python3.8/site-packages/mido/messages/specs.py:127\u001b[0m, in \u001b[0;36mmake_msgdict\u001b[0;34m(type_, overrides)\u001b[0m\n\u001b[1;32m    125\u001b[0m     spec \u001b[39m=\u001b[39m SPEC_BY_TYPE[type_]\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown message type \u001b[39m\u001b[39m{\u001b[39;00mtype_\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    129\u001b[0m msg \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: type_, \u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m: DEFAULT_VALUES[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m spec[\u001b[39m'\u001b[39m\u001b[39mvalue_names\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mLookupError\u001b[0m: Unknown message type 'set_tempo'"
     ]
    }
   ],
   "source": [
    "# Convert piano roll to midi file\n",
    "from pianoroll_to_midi import piano_roll_to_midi\n",
    "\n",
    "midi_out = piano_roll_to_midi(out.to(\"cpu\"))\n",
    "midi_out.save('test.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
